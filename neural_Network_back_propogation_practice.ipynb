{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOv2U9mkkisEgm4ktAJn1Gd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ravindrakumarnayak/Machine_learning/blob/main/neural_Network_back_propogation_practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JjWjKSkeKgnf",
        "outputId": "7c3f52ac-3ec9-4313-b659-3814f39ed7c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensor\n",
            "  Using cached tensor-0.3.6.tar.gz (50 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting flow\n",
            "  Using cached flow-0.1.2.tar.gz (139 kB)\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n"
          ]
        }
      ],
      "source": [
        "! pip install tensor flow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJynOu2XKwn5",
        "outputId": "c85cee10-ab40-4427-e2ae-b0c4700fc6ac"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.12.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ],
      "metadata": {
        "id": "w0tfubZ7LISI"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "EbwjLWzvLh6P"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed=7\n",
        "np.random.seed(seed)"
      ],
      "metadata": {
        "id": "Gd8QlyOOLj9v"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset=np.loadtxt(\"/content/pima-indians-diabetes.csv\", delimiter=',')"
      ],
      "metadata": {
        "id": "vDXj3APpLtTS"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X= dataset[:,0:8]\n",
        "Y= dataset[:,8]"
      ],
      "metadata": {
        "id": "Wsx-4aedL_zg"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5mPG7D8MMEJ",
        "outputId": "cf3c53e1-54ca-46d6-dc44-d0cb29f839b0"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(768, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model=Sequential()\n",
        "model.add(Dense(20, input_dim=8, activation='relu'))\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(10,  activation='relu'))\n",
        "model.add(Dense(1,  activation='sigmoid'))"
      ],
      "metadata": {
        "id": "Mf3rnb7aMR24"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "OuO3_dmDNhay"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history=model.fit(X,Y, validation_split=0.33, epochs=250,batch_size=10 )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VS0PGb92N2mZ",
        "outputId": "8b210d17-02d3-495d-fac3-e468edf3d635"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/250\n",
            "52/52 [==============================] - 2s 7ms/step - loss: 0.8100 - accuracy: 0.6187 - val_loss: 0.7226 - val_accuracy: 0.6260\n",
            "Epoch 2/250\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.6511 - accuracy: 0.6498 - val_loss: 0.6902 - val_accuracy: 0.6063\n",
            "Epoch 3/250\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.6310 - accuracy: 0.6518 - val_loss: 0.6958 - val_accuracy: 0.6575\n",
            "Epoch 4/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6199 - accuracy: 0.6498 - val_loss: 0.6775 - val_accuracy: 0.6378\n",
            "Epoch 5/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6155 - accuracy: 0.6615 - val_loss: 0.6566 - val_accuracy: 0.6299\n",
            "Epoch 6/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6017 - accuracy: 0.6673 - val_loss: 0.6550 - val_accuracy: 0.6102\n",
            "Epoch 7/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6024 - accuracy: 0.6518 - val_loss: 0.6623 - val_accuracy: 0.6142\n",
            "Epoch 8/250\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5907 - accuracy: 0.6732 - val_loss: 0.6498 - val_accuracy: 0.6260\n",
            "Epoch 9/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5904 - accuracy: 0.6770 - val_loss: 0.6695 - val_accuracy: 0.6614\n",
            "Epoch 10/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5983 - accuracy: 0.6654 - val_loss: 0.6292 - val_accuracy: 0.6614\n",
            "Epoch 11/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5788 - accuracy: 0.6809 - val_loss: 0.6414 - val_accuracy: 0.6378\n",
            "Epoch 12/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5816 - accuracy: 0.6770 - val_loss: 0.6375 - val_accuracy: 0.6457\n",
            "Epoch 13/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5769 - accuracy: 0.6829 - val_loss: 0.6537 - val_accuracy: 0.6102\n",
            "Epoch 14/250\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5801 - accuracy: 0.6693 - val_loss: 0.6438 - val_accuracy: 0.6614\n",
            "Epoch 15/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5863 - accuracy: 0.6732 - val_loss: 0.6340 - val_accuracy: 0.6417\n",
            "Epoch 16/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5679 - accuracy: 0.6848 - val_loss: 0.6590 - val_accuracy: 0.6614\n",
            "Epoch 17/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5671 - accuracy: 0.6693 - val_loss: 0.6439 - val_accuracy: 0.6535\n",
            "Epoch 18/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5694 - accuracy: 0.6829 - val_loss: 0.6307 - val_accuracy: 0.6339\n",
            "Epoch 19/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5704 - accuracy: 0.6809 - val_loss: 0.6396 - val_accuracy: 0.6417\n",
            "Epoch 20/250\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5723 - accuracy: 0.6751 - val_loss: 0.6311 - val_accuracy: 0.6772\n",
            "Epoch 21/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5703 - accuracy: 0.6770 - val_loss: 0.6646 - val_accuracy: 0.6102\n",
            "Epoch 22/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5798 - accuracy: 0.6770 - val_loss: 0.6326 - val_accuracy: 0.6575\n",
            "Epoch 23/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5733 - accuracy: 0.6790 - val_loss: 0.6363 - val_accuracy: 0.6378\n",
            "Epoch 24/250\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5743 - accuracy: 0.6790 - val_loss: 0.6234 - val_accuracy: 0.6417\n",
            "Epoch 25/250\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5583 - accuracy: 0.6751 - val_loss: 0.6358 - val_accuracy: 0.6417\n",
            "Epoch 26/250\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5613 - accuracy: 0.6751 - val_loss: 0.6247 - val_accuracy: 0.6496\n",
            "Epoch 27/250\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5565 - accuracy: 0.6926 - val_loss: 0.6298 - val_accuracy: 0.6299\n",
            "Epoch 28/250\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5517 - accuracy: 0.6907 - val_loss: 0.6233 - val_accuracy: 0.6417\n",
            "Epoch 29/250\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5593 - accuracy: 0.6907 - val_loss: 0.6231 - val_accuracy: 0.6535\n",
            "Epoch 30/250\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5665 - accuracy: 0.6848 - val_loss: 0.6174 - val_accuracy: 0.6654\n",
            "Epoch 31/250\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5528 - accuracy: 0.6965 - val_loss: 0.6282 - val_accuracy: 0.6457\n",
            "Epoch 32/250\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5586 - accuracy: 0.6926 - val_loss: 0.6246 - val_accuracy: 0.6654\n",
            "Epoch 33/250\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5477 - accuracy: 0.6926 - val_loss: 0.6392 - val_accuracy: 0.6654\n",
            "Epoch 34/250\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5531 - accuracy: 0.6829 - val_loss: 0.6231 - val_accuracy: 0.6535\n",
            "Epoch 35/250\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5489 - accuracy: 0.6809 - val_loss: 0.6223 - val_accuracy: 0.6535\n",
            "Epoch 36/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5507 - accuracy: 0.6946 - val_loss: 0.6286 - val_accuracy: 0.6496\n",
            "Epoch 37/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5494 - accuracy: 0.6907 - val_loss: 0.6554 - val_accuracy: 0.6457\n",
            "Epoch 38/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5442 - accuracy: 0.6965 - val_loss: 0.6200 - val_accuracy: 0.6693\n",
            "Epoch 39/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5422 - accuracy: 0.6926 - val_loss: 0.6353 - val_accuracy: 0.6772\n",
            "Epoch 40/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5472 - accuracy: 0.6965 - val_loss: 0.6359 - val_accuracy: 0.6457\n",
            "Epoch 41/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5432 - accuracy: 0.7043 - val_loss: 0.6386 - val_accuracy: 0.6339\n",
            "Epoch 42/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5384 - accuracy: 0.7121 - val_loss: 0.6226 - val_accuracy: 0.6496\n",
            "Epoch 43/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5448 - accuracy: 0.7004 - val_loss: 0.6432 - val_accuracy: 0.6339\n",
            "Epoch 44/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5491 - accuracy: 0.6984 - val_loss: 0.6466 - val_accuracy: 0.6614\n",
            "Epoch 45/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5411 - accuracy: 0.6984 - val_loss: 0.6299 - val_accuracy: 0.6575\n",
            "Epoch 46/250\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5646 - accuracy: 0.6848 - val_loss: 0.6269 - val_accuracy: 0.6535\n",
            "Epoch 47/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5384 - accuracy: 0.7082 - val_loss: 0.6382 - val_accuracy: 0.6654\n",
            "Epoch 48/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5511 - accuracy: 0.6790 - val_loss: 0.6375 - val_accuracy: 0.6654\n",
            "Epoch 49/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5318 - accuracy: 0.7023 - val_loss: 0.6238 - val_accuracy: 0.6496\n",
            "Epoch 50/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5396 - accuracy: 0.6926 - val_loss: 0.6479 - val_accuracy: 0.6378\n",
            "Epoch 51/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5264 - accuracy: 0.6946 - val_loss: 0.6598 - val_accuracy: 0.6299\n",
            "Epoch 52/250\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5704 - accuracy: 0.6595 - val_loss: 0.6154 - val_accuracy: 0.6535\n",
            "Epoch 53/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5399 - accuracy: 0.6926 - val_loss: 0.6136 - val_accuracy: 0.6654\n",
            "Epoch 54/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5249 - accuracy: 0.7023 - val_loss: 0.6486 - val_accuracy: 0.6378\n",
            "Epoch 55/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5289 - accuracy: 0.6946 - val_loss: 0.6321 - val_accuracy: 0.6535\n",
            "Epoch 56/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5378 - accuracy: 0.6868 - val_loss: 0.6397 - val_accuracy: 0.6535\n",
            "Epoch 57/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5290 - accuracy: 0.6984 - val_loss: 0.6300 - val_accuracy: 0.6772\n",
            "Epoch 58/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5218 - accuracy: 0.7023 - val_loss: 0.6180 - val_accuracy: 0.6496\n",
            "Epoch 59/250\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5193 - accuracy: 0.7140 - val_loss: 0.6386 - val_accuracy: 0.6575\n",
            "Epoch 60/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5305 - accuracy: 0.7121 - val_loss: 0.6143 - val_accuracy: 0.6654\n",
            "Epoch 61/250\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.5163 - accuracy: 0.7121 - val_loss: 0.6659 - val_accuracy: 0.6654\n",
            "Epoch 62/250\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5343 - accuracy: 0.6887 - val_loss: 0.6340 - val_accuracy: 0.6535\n",
            "Epoch 63/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5389 - accuracy: 0.7004 - val_loss: 0.6389 - val_accuracy: 0.6732\n",
            "Epoch 64/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5144 - accuracy: 0.7062 - val_loss: 0.6180 - val_accuracy: 0.6654\n",
            "Epoch 65/250\n",
            "52/52 [==============================] - 1s 10ms/step - loss: 0.5266 - accuracy: 0.6790 - val_loss: 0.6256 - val_accuracy: 0.6929\n",
            "Epoch 66/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5185 - accuracy: 0.7062 - val_loss: 0.6278 - val_accuracy: 0.6614\n",
            "Epoch 67/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5252 - accuracy: 0.7121 - val_loss: 0.6176 - val_accuracy: 0.6654\n",
            "Epoch 68/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5165 - accuracy: 0.6984 - val_loss: 0.6234 - val_accuracy: 0.6496\n",
            "Epoch 69/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5166 - accuracy: 0.7121 - val_loss: 0.6130 - val_accuracy: 0.6457\n",
            "Epoch 70/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5331 - accuracy: 0.7121 - val_loss: 0.6320 - val_accuracy: 0.6772\n",
            "Epoch 71/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5185 - accuracy: 0.6868 - val_loss: 0.6098 - val_accuracy: 0.6811\n",
            "Epoch 72/250\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5190 - accuracy: 0.6984 - val_loss: 0.6207 - val_accuracy: 0.6496\n",
            "Epoch 73/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5096 - accuracy: 0.7101 - val_loss: 0.6207 - val_accuracy: 0.6654\n",
            "Epoch 74/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5148 - accuracy: 0.6984 - val_loss: 0.6419 - val_accuracy: 0.6811\n",
            "Epoch 75/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5271 - accuracy: 0.6926 - val_loss: 0.6233 - val_accuracy: 0.6654\n",
            "Epoch 76/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5147 - accuracy: 0.7043 - val_loss: 0.6429 - val_accuracy: 0.6378\n",
            "Epoch 77/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5274 - accuracy: 0.7198 - val_loss: 0.6183 - val_accuracy: 0.6654\n",
            "Epoch 78/250\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5077 - accuracy: 0.7218 - val_loss: 0.6295 - val_accuracy: 0.6575\n",
            "Epoch 79/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5224 - accuracy: 0.7023 - val_loss: 0.6363 - val_accuracy: 0.6614\n",
            "Epoch 80/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5076 - accuracy: 0.7218 - val_loss: 0.7050 - val_accuracy: 0.6614\n",
            "Epoch 81/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5197 - accuracy: 0.6965 - val_loss: 0.6316 - val_accuracy: 0.6535\n",
            "Epoch 82/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5067 - accuracy: 0.7101 - val_loss: 0.6560 - val_accuracy: 0.6496\n",
            "Epoch 83/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5124 - accuracy: 0.7160 - val_loss: 0.6125 - val_accuracy: 0.6693\n",
            "Epoch 84/250\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5147 - accuracy: 0.6984 - val_loss: 0.6340 - val_accuracy: 0.6575\n",
            "Epoch 85/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5226 - accuracy: 0.7062 - val_loss: 0.6297 - val_accuracy: 0.6535\n",
            "Epoch 86/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5036 - accuracy: 0.7237 - val_loss: 0.6384 - val_accuracy: 0.6654\n",
            "Epoch 87/250\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5086 - accuracy: 0.7062 - val_loss: 0.6176 - val_accuracy: 0.6732\n",
            "Epoch 88/250\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4993 - accuracy: 0.7160 - val_loss: 0.6345 - val_accuracy: 0.6772\n",
            "Epoch 89/250\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.5075 - accuracy: 0.7082 - val_loss: 0.6516 - val_accuracy: 0.6614\n",
            "Epoch 90/250\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5156 - accuracy: 0.7082 - val_loss: 0.6277 - val_accuracy: 0.6693\n",
            "Epoch 91/250\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5147 - accuracy: 0.7004 - val_loss: 0.6351 - val_accuracy: 0.6654\n",
            "Epoch 92/250\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5015 - accuracy: 0.7101 - val_loss: 0.6182 - val_accuracy: 0.6575\n",
            "Epoch 93/250\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5054 - accuracy: 0.7023 - val_loss: 0.6128 - val_accuracy: 0.6811\n",
            "Epoch 94/250\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4989 - accuracy: 0.7160 - val_loss: 0.6507 - val_accuracy: 0.6732\n",
            "Epoch 95/250\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5118 - accuracy: 0.7101 - val_loss: 0.6034 - val_accuracy: 0.6772\n",
            "Epoch 96/250\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5015 - accuracy: 0.7101 - val_loss: 0.6302 - val_accuracy: 0.6575\n",
            "Epoch 97/250\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5161 - accuracy: 0.7082 - val_loss: 0.6413 - val_accuracy: 0.6457\n",
            "Epoch 98/250\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4999 - accuracy: 0.7062 - val_loss: 0.6340 - val_accuracy: 0.6654\n",
            "Epoch 99/250\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4984 - accuracy: 0.7121 - val_loss: 0.6400 - val_accuracy: 0.6654\n",
            "Epoch 100/250\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4917 - accuracy: 0.7198 - val_loss: 0.6467 - val_accuracy: 0.6654\n",
            "Epoch 101/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5073 - accuracy: 0.7160 - val_loss: 0.6316 - val_accuracy: 0.6850\n",
            "Epoch 102/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4912 - accuracy: 0.7160 - val_loss: 0.6525 - val_accuracy: 0.6614\n",
            "Epoch 103/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5104 - accuracy: 0.7101 - val_loss: 0.6376 - val_accuracy: 0.6575\n",
            "Epoch 104/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4919 - accuracy: 0.7315 - val_loss: 0.6443 - val_accuracy: 0.6654\n",
            "Epoch 105/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4935 - accuracy: 0.7121 - val_loss: 0.6162 - val_accuracy: 0.6693\n",
            "Epoch 106/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4996 - accuracy: 0.7140 - val_loss: 0.6291 - val_accuracy: 0.6575\n",
            "Epoch 107/250\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4912 - accuracy: 0.6984 - val_loss: 0.6884 - val_accuracy: 0.6496\n",
            "Epoch 108/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5100 - accuracy: 0.7062 - val_loss: 0.6379 - val_accuracy: 0.6654\n",
            "Epoch 109/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5015 - accuracy: 0.7160 - val_loss: 0.6263 - val_accuracy: 0.6575\n",
            "Epoch 110/250\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4941 - accuracy: 0.7257 - val_loss: 0.6359 - val_accuracy: 0.6575\n",
            "Epoch 111/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4886 - accuracy: 0.7101 - val_loss: 0.6654 - val_accuracy: 0.6417\n",
            "Epoch 112/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5004 - accuracy: 0.7121 - val_loss: 0.6210 - val_accuracy: 0.6535\n",
            "Epoch 113/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5025 - accuracy: 0.7082 - val_loss: 0.6347 - val_accuracy: 0.6850\n",
            "Epoch 114/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5005 - accuracy: 0.7160 - val_loss: 0.6423 - val_accuracy: 0.6811\n",
            "Epoch 115/250\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4927 - accuracy: 0.7043 - val_loss: 0.6664 - val_accuracy: 0.6496\n",
            "Epoch 116/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4820 - accuracy: 0.7315 - val_loss: 0.6598 - val_accuracy: 0.6496\n",
            "Epoch 117/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4836 - accuracy: 0.7198 - val_loss: 0.6515 - val_accuracy: 0.6457\n",
            "Epoch 118/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4880 - accuracy: 0.7140 - val_loss: 0.6769 - val_accuracy: 0.6496\n",
            "Epoch 119/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4923 - accuracy: 0.7121 - val_loss: 0.6531 - val_accuracy: 0.6378\n",
            "Epoch 120/250\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4852 - accuracy: 0.7276 - val_loss: 0.6768 - val_accuracy: 0.6339\n",
            "Epoch 121/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4830 - accuracy: 0.7335 - val_loss: 0.6679 - val_accuracy: 0.6535\n",
            "Epoch 122/250\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4869 - accuracy: 0.7198 - val_loss: 0.6841 - val_accuracy: 0.6575\n",
            "Epoch 123/250\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4814 - accuracy: 0.7237 - val_loss: 0.6411 - val_accuracy: 0.6732\n",
            "Epoch 124/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4838 - accuracy: 0.7335 - val_loss: 0.6463 - val_accuracy: 0.6614\n",
            "Epoch 125/250\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4904 - accuracy: 0.7023 - val_loss: 0.6541 - val_accuracy: 0.6614\n",
            "Epoch 126/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4746 - accuracy: 0.7237 - val_loss: 0.6770 - val_accuracy: 0.6614\n",
            "Epoch 127/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4849 - accuracy: 0.7276 - val_loss: 0.6397 - val_accuracy: 0.6614\n",
            "Epoch 128/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4825 - accuracy: 0.7257 - val_loss: 0.6547 - val_accuracy: 0.6772\n",
            "Epoch 129/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4886 - accuracy: 0.7276 - val_loss: 0.6665 - val_accuracy: 0.6575\n",
            "Epoch 130/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4945 - accuracy: 0.7179 - val_loss: 0.6497 - val_accuracy: 0.6732\n",
            "Epoch 131/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5024 - accuracy: 0.7160 - val_loss: 0.6622 - val_accuracy: 0.6732\n",
            "Epoch 132/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4971 - accuracy: 0.7043 - val_loss: 0.6414 - val_accuracy: 0.6457\n",
            "Epoch 133/250\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4666 - accuracy: 0.7315 - val_loss: 0.6598 - val_accuracy: 0.6732\n",
            "Epoch 134/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4829 - accuracy: 0.7315 - val_loss: 0.6595 - val_accuracy: 0.6654\n",
            "Epoch 135/250\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4700 - accuracy: 0.7198 - val_loss: 0.6746 - val_accuracy: 0.6575\n",
            "Epoch 136/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4794 - accuracy: 0.7296 - val_loss: 0.6548 - val_accuracy: 0.6772\n",
            "Epoch 137/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4760 - accuracy: 0.7354 - val_loss: 0.6634 - val_accuracy: 0.6457\n",
            "Epoch 138/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4718 - accuracy: 0.7393 - val_loss: 0.6640 - val_accuracy: 0.6654\n",
            "Epoch 139/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4812 - accuracy: 0.7315 - val_loss: 0.6693 - val_accuracy: 0.6575\n",
            "Epoch 140/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4745 - accuracy: 0.7257 - val_loss: 0.6564 - val_accuracy: 0.6614\n",
            "Epoch 141/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4781 - accuracy: 0.7296 - val_loss: 0.6854 - val_accuracy: 0.6457\n",
            "Epoch 142/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4683 - accuracy: 0.7276 - val_loss: 0.6669 - val_accuracy: 0.6654\n",
            "Epoch 143/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4683 - accuracy: 0.7374 - val_loss: 0.6760 - val_accuracy: 0.6535\n",
            "Epoch 144/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4848 - accuracy: 0.7198 - val_loss: 0.6472 - val_accuracy: 0.6772\n",
            "Epoch 145/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4700 - accuracy: 0.7296 - val_loss: 0.6625 - val_accuracy: 0.6732\n",
            "Epoch 146/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4809 - accuracy: 0.7393 - val_loss: 0.6499 - val_accuracy: 0.6693\n",
            "Epoch 147/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4723 - accuracy: 0.7354 - val_loss: 0.6387 - val_accuracy: 0.6811\n",
            "Epoch 148/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4717 - accuracy: 0.7335 - val_loss: 0.6791 - val_accuracy: 0.6654\n",
            "Epoch 149/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4700 - accuracy: 0.7257 - val_loss: 0.6561 - val_accuracy: 0.6693\n",
            "Epoch 150/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4661 - accuracy: 0.7276 - val_loss: 0.6537 - val_accuracy: 0.6614\n",
            "Epoch 151/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4651 - accuracy: 0.7393 - val_loss: 0.6500 - val_accuracy: 0.6732\n",
            "Epoch 152/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4712 - accuracy: 0.7198 - val_loss: 0.6592 - val_accuracy: 0.6772\n",
            "Epoch 153/250\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4658 - accuracy: 0.7335 - val_loss: 0.6680 - val_accuracy: 0.6614\n",
            "Epoch 154/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4677 - accuracy: 0.7354 - val_loss: 0.6648 - val_accuracy: 0.6732\n",
            "Epoch 155/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4628 - accuracy: 0.7432 - val_loss: 0.6539 - val_accuracy: 0.6772\n",
            "Epoch 156/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4617 - accuracy: 0.7276 - val_loss: 0.6619 - val_accuracy: 0.6654\n",
            "Epoch 157/250\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4823 - accuracy: 0.7257 - val_loss: 0.6835 - val_accuracy: 0.6457\n",
            "Epoch 158/250\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4662 - accuracy: 0.7432 - val_loss: 0.6570 - val_accuracy: 0.6811\n",
            "Epoch 159/250\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4835 - accuracy: 0.7198 - val_loss: 0.6536 - val_accuracy: 0.6850\n",
            "Epoch 160/250\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4724 - accuracy: 0.7276 - val_loss: 0.6518 - val_accuracy: 0.6811\n",
            "Epoch 161/250\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4564 - accuracy: 0.7393 - val_loss: 0.6599 - val_accuracy: 0.6811\n",
            "Epoch 162/250\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4693 - accuracy: 0.7276 - val_loss: 0.6748 - val_accuracy: 0.6614\n",
            "Epoch 163/250\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4727 - accuracy: 0.7490 - val_loss: 0.6759 - val_accuracy: 0.6614\n",
            "Epoch 164/250\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4654 - accuracy: 0.7296 - val_loss: 0.6740 - val_accuracy: 0.6654\n",
            "Epoch 165/250\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4718 - accuracy: 0.7296 - val_loss: 0.6712 - val_accuracy: 0.6693\n",
            "Epoch 166/250\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4609 - accuracy: 0.7335 - val_loss: 0.7082 - val_accuracy: 0.6496\n",
            "Epoch 167/250\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4585 - accuracy: 0.7257 - val_loss: 0.6747 - val_accuracy: 0.6535\n",
            "Epoch 168/250\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4626 - accuracy: 0.7374 - val_loss: 0.6776 - val_accuracy: 0.6811\n",
            "Epoch 169/250\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4844 - accuracy: 0.7335 - val_loss: 0.6979 - val_accuracy: 0.6024\n",
            "Epoch 170/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4837 - accuracy: 0.7218 - val_loss: 0.7395 - val_accuracy: 0.6496\n",
            "Epoch 171/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4736 - accuracy: 0.7276 - val_loss: 0.6953 - val_accuracy: 0.6535\n",
            "Epoch 172/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4717 - accuracy: 0.7412 - val_loss: 0.7117 - val_accuracy: 0.6575\n",
            "Epoch 173/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4820 - accuracy: 0.7082 - val_loss: 0.7072 - val_accuracy: 0.6614\n",
            "Epoch 174/250\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4702 - accuracy: 0.7315 - val_loss: 0.6575 - val_accuracy: 0.6693\n",
            "Epoch 175/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4647 - accuracy: 0.7179 - val_loss: 0.6898 - val_accuracy: 0.6772\n",
            "Epoch 176/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4602 - accuracy: 0.7451 - val_loss: 0.6652 - val_accuracy: 0.6969\n",
            "Epoch 177/250\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4584 - accuracy: 0.7646 - val_loss: 0.6985 - val_accuracy: 0.7008\n",
            "Epoch 178/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4590 - accuracy: 0.7743 - val_loss: 0.6865 - val_accuracy: 0.6929\n",
            "Epoch 179/250\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4683 - accuracy: 0.7743 - val_loss: 0.6839 - val_accuracy: 0.6969\n",
            "Epoch 180/250\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4651 - accuracy: 0.7646 - val_loss: 0.6790 - val_accuracy: 0.6969\n",
            "Epoch 181/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4568 - accuracy: 0.7821 - val_loss: 0.6923 - val_accuracy: 0.6850\n",
            "Epoch 182/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4678 - accuracy: 0.7685 - val_loss: 0.6809 - val_accuracy: 0.7008\n",
            "Epoch 183/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4521 - accuracy: 0.7782 - val_loss: 0.6735 - val_accuracy: 0.7087\n",
            "Epoch 184/250\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4519 - accuracy: 0.7860 - val_loss: 0.6961 - val_accuracy: 0.7008\n",
            "Epoch 185/250\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4499 - accuracy: 0.7899 - val_loss: 0.7172 - val_accuracy: 0.7008\n",
            "Epoch 186/250\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4686 - accuracy: 0.7490 - val_loss: 0.7384 - val_accuracy: 0.6417\n",
            "Epoch 187/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4702 - accuracy: 0.7802 - val_loss: 0.6701 - val_accuracy: 0.7008\n",
            "Epoch 188/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4603 - accuracy: 0.7724 - val_loss: 0.6775 - val_accuracy: 0.7362\n",
            "Epoch 189/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4508 - accuracy: 0.7763 - val_loss: 0.7013 - val_accuracy: 0.6850\n",
            "Epoch 190/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4697 - accuracy: 0.7568 - val_loss: 0.6972 - val_accuracy: 0.7047\n",
            "Epoch 191/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4579 - accuracy: 0.7724 - val_loss: 0.6732 - val_accuracy: 0.7126\n",
            "Epoch 192/250\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4588 - accuracy: 0.7782 - val_loss: 0.7158 - val_accuracy: 0.6811\n",
            "Epoch 193/250\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4489 - accuracy: 0.7860 - val_loss: 0.6827 - val_accuracy: 0.6890\n",
            "Epoch 194/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4512 - accuracy: 0.7802 - val_loss: 0.6938 - val_accuracy: 0.7008\n",
            "Epoch 195/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4516 - accuracy: 0.7704 - val_loss: 0.6857 - val_accuracy: 0.7283\n",
            "Epoch 196/250\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4513 - accuracy: 0.7840 - val_loss: 0.6908 - val_accuracy: 0.7008\n",
            "Epoch 197/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4460 - accuracy: 0.7802 - val_loss: 0.6875 - val_accuracy: 0.6890\n",
            "Epoch 198/250\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4485 - accuracy: 0.7879 - val_loss: 0.7315 - val_accuracy: 0.6890\n",
            "Epoch 199/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4610 - accuracy: 0.7763 - val_loss: 0.6970 - val_accuracy: 0.6890\n",
            "Epoch 200/250\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4540 - accuracy: 0.7743 - val_loss: 0.7016 - val_accuracy: 0.7008\n",
            "Epoch 201/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4479 - accuracy: 0.7724 - val_loss: 0.7138 - val_accuracy: 0.6850\n",
            "Epoch 202/250\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4479 - accuracy: 0.7568 - val_loss: 0.6937 - val_accuracy: 0.6969\n",
            "Epoch 203/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4577 - accuracy: 0.7802 - val_loss: 0.7934 - val_accuracy: 0.6614\n",
            "Epoch 204/250\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4670 - accuracy: 0.7549 - val_loss: 0.6958 - val_accuracy: 0.7087\n",
            "Epoch 205/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4525 - accuracy: 0.7724 - val_loss: 0.7230 - val_accuracy: 0.6811\n",
            "Epoch 206/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4584 - accuracy: 0.7763 - val_loss: 0.6804 - val_accuracy: 0.6929\n",
            "Epoch 207/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4478 - accuracy: 0.7704 - val_loss: 0.7259 - val_accuracy: 0.7047\n",
            "Epoch 208/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4729 - accuracy: 0.7724 - val_loss: 0.6728 - val_accuracy: 0.7087\n",
            "Epoch 209/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4546 - accuracy: 0.7626 - val_loss: 0.6940 - val_accuracy: 0.7165\n",
            "Epoch 210/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4493 - accuracy: 0.7899 - val_loss: 0.7268 - val_accuracy: 0.6811\n",
            "Epoch 211/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4656 - accuracy: 0.7529 - val_loss: 0.7281 - val_accuracy: 0.6220\n",
            "Epoch 212/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4593 - accuracy: 0.7763 - val_loss: 0.6861 - val_accuracy: 0.7008\n",
            "Epoch 213/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4417 - accuracy: 0.7646 - val_loss: 0.7258 - val_accuracy: 0.6496\n",
            "Epoch 214/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4596 - accuracy: 0.7763 - val_loss: 0.7026 - val_accuracy: 0.6850\n",
            "Epoch 215/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4396 - accuracy: 0.7626 - val_loss: 0.7737 - val_accuracy: 0.6811\n",
            "Epoch 216/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4606 - accuracy: 0.7665 - val_loss: 0.7378 - val_accuracy: 0.6378\n",
            "Epoch 217/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4745 - accuracy: 0.7724 - val_loss: 0.7314 - val_accuracy: 0.6890\n",
            "Epoch 218/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4578 - accuracy: 0.7821 - val_loss: 0.7132 - val_accuracy: 0.7047\n",
            "Epoch 219/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4395 - accuracy: 0.7724 - val_loss: 0.7017 - val_accuracy: 0.6654\n",
            "Epoch 220/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4576 - accuracy: 0.7724 - val_loss: 0.6979 - val_accuracy: 0.6969\n",
            "Epoch 221/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4452 - accuracy: 0.7821 - val_loss: 0.7329 - val_accuracy: 0.6969\n",
            "Epoch 222/250\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4782 - accuracy: 0.7490 - val_loss: 0.7658 - val_accuracy: 0.6299\n",
            "Epoch 223/250\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4515 - accuracy: 0.7860 - val_loss: 0.7399 - val_accuracy: 0.6732\n",
            "Epoch 224/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4575 - accuracy: 0.7685 - val_loss: 0.6870 - val_accuracy: 0.7047\n",
            "Epoch 225/250\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4607 - accuracy: 0.7743 - val_loss: 0.7084 - val_accuracy: 0.6929\n",
            "Epoch 226/250\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4405 - accuracy: 0.7840 - val_loss: 0.7352 - val_accuracy: 0.6772\n",
            "Epoch 227/250\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4467 - accuracy: 0.7938 - val_loss: 0.7211 - val_accuracy: 0.6693\n",
            "Epoch 228/250\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4449 - accuracy: 0.7782 - val_loss: 0.7276 - val_accuracy: 0.6535\n",
            "Epoch 229/250\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4630 - accuracy: 0.7899 - val_loss: 0.6717 - val_accuracy: 0.6890\n",
            "Epoch 230/250\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4508 - accuracy: 0.7626 - val_loss: 0.6788 - val_accuracy: 0.6929\n",
            "Epoch 231/250\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4403 - accuracy: 0.7957 - val_loss: 0.7449 - val_accuracy: 0.6929\n",
            "Epoch 232/250\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4426 - accuracy: 0.7821 - val_loss: 0.7181 - val_accuracy: 0.7008\n",
            "Epoch 233/250\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4476 - accuracy: 0.7860 - val_loss: 0.7601 - val_accuracy: 0.6732\n",
            "Epoch 234/250\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4385 - accuracy: 0.7996 - val_loss: 0.7104 - val_accuracy: 0.6811\n",
            "Epoch 235/250\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4687 - accuracy: 0.7412 - val_loss: 0.7297 - val_accuracy: 0.6811\n",
            "Epoch 236/250\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4491 - accuracy: 0.7763 - val_loss: 0.7219 - val_accuracy: 0.7008\n",
            "Epoch 237/250\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4398 - accuracy: 0.7802 - val_loss: 0.7335 - val_accuracy: 0.7165\n",
            "Epoch 238/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4554 - accuracy: 0.7704 - val_loss: 0.7361 - val_accuracy: 0.6890\n",
            "Epoch 239/250\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4341 - accuracy: 0.7938 - val_loss: 0.7363 - val_accuracy: 0.6890\n",
            "Epoch 240/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4373 - accuracy: 0.7840 - val_loss: 0.7269 - val_accuracy: 0.7087\n",
            "Epoch 241/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4348 - accuracy: 0.7918 - val_loss: 0.7472 - val_accuracy: 0.6969\n",
            "Epoch 242/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4421 - accuracy: 0.7879 - val_loss: 0.7887 - val_accuracy: 0.6693\n",
            "Epoch 243/250\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4599 - accuracy: 0.7782 - val_loss: 0.7232 - val_accuracy: 0.7087\n",
            "Epoch 244/250\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4429 - accuracy: 0.7899 - val_loss: 0.7029 - val_accuracy: 0.7087\n",
            "Epoch 245/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4337 - accuracy: 0.7918 - val_loss: 0.7125 - val_accuracy: 0.7008\n",
            "Epoch 246/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4301 - accuracy: 0.7996 - val_loss: 0.7248 - val_accuracy: 0.6772\n",
            "Epoch 247/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4517 - accuracy: 0.7704 - val_loss: 0.7479 - val_accuracy: 0.6969\n",
            "Epoch 248/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4694 - accuracy: 0.7763 - val_loss: 0.7912 - val_accuracy: 0.6732\n",
            "Epoch 249/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4431 - accuracy: 0.7724 - val_loss: 0.7594 - val_accuracy: 0.6457\n",
            "Epoch 250/250\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4479 - accuracy: 0.7860 - val_loss: 0.7103 - val_accuracy: 0.6929\n"
          ]
        }
      ]
    }
  ]
}