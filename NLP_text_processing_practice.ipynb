{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPrfc0HGSpNCpLsyUogTJi3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ravindrakumarnayak/Machine_learning/blob/main/NLP_text_processing_practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jBxaaVOAS9C",
        "outputId": "ab5456c2-5675-4150-f158-58722e5eeccb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.6)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2022.10.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.65.0)\n"
          ]
        }
      ],
      "source": [
        "! pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download(\"punkt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5Qn94aBAvNg",
        "outputId": "03ee90aa-44c1-469f-ba64-bd97241c4a7a"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download(\"wordnet\")\n",
        "nltk.download(\"stopwords\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jg453PxzA6Pa",
        "outputId": "cb10c883-c5db-4542-bf5a-343144458849"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download(\"omw-1.4\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzaStX1vBM8G",
        "outputId": "31c5607d-c5ee-474b-90d4-1d475c61085e"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "id": "ndDb2Pb3BTAE"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "id": "dHm8BwqYBzd2"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "para=\"\"\"‚Äî Tensor and Tensorflow: A powerful combo üí™\n",
        "The Google Brain team developed an advanced AI framework named Tensorflow years back. After that, Google designed its own processing unit named Tensor Processing Unit or TPU to perform more efficiently with the Tensorflow. The invention of TPU was a revolution in AI that has significantly expedited the training of huge machine learning models with millions (or, billions) of parameters. Nevertheless, that technology could not be used in low-power devices such as smartphones in Edge AI. The entrance of Google into the AI chip manufacturing club for low-power devices can be the next revolution in this industry. Many companies such as FogHorn and BlinkAI are working in Edge AI using currently existing AI chips in the market. However, the efficacy that Google can create by the combination of TensorFlow and Tensor will be game-changing. Welcome to the club, Google!\n",
        "\n",
        "‚Äî Tensor is an AI chip designed by AI! üò≤\n",
        "Isn‚Äôt that cool? The story is started from an article published in Nature titles ‚ÄúA graph placement methodology for fast chip design‚Äù. To design a processing chip, there is a crucial step referred to as ‚Äúfloor planning‚Äù where the engineering team must place a large number of components such that a series of physical requirements including power consumption and performance get satisfied. I don‚Äôt go further into its details as I am also not an expert in hardware engineering. However, when you have a large series of choices to make with a series of constraints AI can kick in. You may remember how the AlphaGo project defeated a professional human Go player. This is exactly the same. Tensor is the real outcome of this project that is a new milestone in the AI industry. Kudos, Google!\n",
        "\n",
        "‚Äî Tensor helps us build ethical AI. üí°\n",
        "This is a double-edged sword statement. Ethical AI has various aspects from data privacy to AI for all. Tensor helps many users have the opportunity to try the latest AI advancement while they have no concern about their privacy. Why? Because the AI engine is running on the chip, and no data is sent to the cloud for further computation. On the other hand, the more tightly Google binds AI software and hardware, the harder it will be for other companies to compete. I don‚Äôt want to see days that other companies can not even compete on performing AI inference, i.e., compete on using AI. We almost lost the game of model training to giant tech companies. It would be a nightmare if we lose the game on AI inference to them as well. That is why I believe ‚ÄúTensor helps us build ethical AI‚Äù is a double-edged sword.\"\"\""
      ],
      "metadata": {
        "id": "b6MO0BRZB25r"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "para"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "2jiSdMscCCJX",
        "outputId": "64b3f99e-a894-42ed-ac72-0f67369e0428"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'‚Äî Tensor and Tensorflow: A powerful combo üí™\\nThe Google Brain team developed an advanced AI framework named Tensorflow years back. After that, Google designed its own processing unit named Tensor Processing Unit or TPU to perform more efficiently with the Tensorflow. The invention of TPU was a revolution in AI that has significantly expedited the training of huge machine learning models with millions (or, billions) of parameters. Nevertheless, that technology could not be used in low-power devices such as smartphones in Edge AI. The entrance of Google into the AI chip manufacturing club for low-power devices can be the next revolution in this industry. Many companies such as FogHorn and BlinkAI are working in Edge AI using currently existing AI chips in the market. However, the efficacy that Google can create by the combination of TensorFlow and Tensor will be game-changing. Welcome to the club, Google!\\n\\n‚Äî Tensor is an AI chip designed by AI! üò≤\\nIsn‚Äôt that cool? The story is started from an article published in Nature titles ‚ÄúA graph placement methodology for fast chip design‚Äù. To design a processing chip, there is a crucial step referred to as ‚Äúfloor planning‚Äù where the engineering team must place a large number of components such that a series of physical requirements including power consumption and performance get satisfied. I don‚Äôt go further into its details as I am also not an expert in hardware engineering. However, when you have a large series of choices to make with a series of constraints AI can kick in. You may remember how the AlphaGo project defeated a professional human Go player. This is exactly the same. Tensor is the real outcome of this project that is a new milestone in the AI industry. Kudos, Google!\\n\\n‚Äî Tensor helps us build ethical AI. üí°\\nThis is a double-edged sword statement. Ethical AI has various aspects from data privacy to AI for all. Tensor helps many users have the opportunity to try the latest AI advancement while they have no concern about their privacy. Why? Because the AI engine is running on the chip, and no data is sent to the cloud for further computation. On the other hand, the more tightly Google binds AI software and hardware, the harder it will be for other companies to compete. I don‚Äôt want to see days that other companies can not even compete on performing AI inference, i.e., compete on using AI. We almost lost the game of model training to giant tech companies. It would be a nightmare if we lose the game on AI inference to them as well. That is why I believe ‚ÄúTensor helps us build ethical AI‚Äù is a double-edged sword.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(para) # return number of characters in para"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCHqOd0DCC6N",
        "outputId": "16e1e8b6-a4ef-4570-9b6d-22c0a30429b5"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2602"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "document=\"We are learning Tokenization in NLP\"  # for practice how tokenization function work\n",
        "nltk.word_tokenize(document)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQdUrgfqCTVQ",
        "outputId": "b3cfa09d-cbd8-4fc0-e370-c13cafd0ab56"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['We', 'are', 'learning', 'Tokenization', 'in', 'NLP']"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sent= nltk.sent_tokenize(para)"
      ],
      "metadata": {
        "id": "bHCE_jhkCvkL"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77xU7KrzDfId",
        "outputId": "9f8a7bb1-3ce2-4888-a37b-579d3d5906e8"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['‚Äî Tensor and Tensorflow: A powerful combo üí™\\nThe Google Brain team developed an advanced AI framework named Tensorflow years back.',\n",
              " 'After that, Google designed its own processing unit named Tensor Processing Unit or TPU to perform more efficiently with the Tensorflow.',\n",
              " 'The invention of TPU was a revolution in AI that has significantly expedited the training of huge machine learning models with millions (or, billions) of parameters.',\n",
              " 'Nevertheless, that technology could not be used in low-power devices such as smartphones in Edge AI.',\n",
              " 'The entrance of Google into the AI chip manufacturing club for low-power devices can be the next revolution in this industry.',\n",
              " 'Many companies such as FogHorn and BlinkAI are working in Edge AI using currently existing AI chips in the market.',\n",
              " 'However, the efficacy that Google can create by the combination of TensorFlow and Tensor will be game-changing.',\n",
              " 'Welcome to the club, Google!',\n",
              " '‚Äî Tensor is an AI chip designed by AI!',\n",
              " 'üò≤\\nIsn‚Äôt that cool?',\n",
              " 'The story is started from an article published in Nature titles ‚ÄúA graph placement methodology for fast chip design‚Äù.',\n",
              " 'To design a processing chip, there is a crucial step referred to as ‚Äúfloor planning‚Äù where the engineering team must place a large number of components such that a series of physical requirements including power consumption and performance get satisfied.',\n",
              " 'I don‚Äôt go further into its details as I am also not an expert in hardware engineering.',\n",
              " 'However, when you have a large series of choices to make with a series of constraints AI can kick in.',\n",
              " 'You may remember how the AlphaGo project defeated a professional human Go player.',\n",
              " 'This is exactly the same.',\n",
              " 'Tensor is the real outcome of this project that is a new milestone in the AI industry.',\n",
              " 'Kudos, Google!',\n",
              " '‚Äî Tensor helps us build ethical AI.',\n",
              " 'üí°\\nThis is a double-edged sword statement.',\n",
              " 'Ethical AI has various aspects from data privacy to AI for all.',\n",
              " 'Tensor helps many users have the opportunity to try the latest AI advancement while they have no concern about their privacy.',\n",
              " 'Why?',\n",
              " 'Because the AI engine is running on the chip, and no data is sent to the cloud for further computation.',\n",
              " 'On the other hand, the more tightly Google binds AI software and hardware, the harder it will be for other companies to compete.',\n",
              " 'I don‚Äôt want to see days that other companies can not even compete on performing AI inference, i.e., compete on using AI.',\n",
              " 'We almost lost the game of model training to giant tech companies.',\n",
              " 'It would be a nightmare if we lose the game on AI inference to them as well.',\n",
              " 'That is why I believe ‚ÄúTensor helps us build ethical AI‚Äù is a double-edged sword.']"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(sent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrF3xRfMDf-i",
        "outputId": "eed9fe8f-2ef9-42d9-e4b3-c9b5167e96a4"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "29"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bqfTsSJaDkFF"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus=[]\n",
        "\n",
        "for i in range(len(sent)):\n",
        "   txt=re.sub('[^a-zA-Z]','  ', sent[i])\n",
        "   txt=txt.lower()\n",
        "\n",
        "\n",
        "   corpus.append(txt)"
      ],
      "metadata": {
        "id": "koxoX_BnDntq"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lEfXuWfoD80S",
        "outputId": "5cad7d77-32f7-4188-8cb3-451add2ddec3"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['    tensor  and  tensorflow    a  powerful  combo      the  google  brain  team  developed  an  advanced  ai  framework  named  tensorflow  years  back  ',\n",
              " 'after  that    google  designed  its  own  processing  unit  named  tensor  processing  unit  or  tpu  to  perform  more  efficiently  with  the  tensorflow  ',\n",
              " 'the  invention  of  tpu  was  a  revolution  in  ai  that  has  significantly  expedited  the  training  of  huge  machine  learning  models  with  millions    or    billions    of  parameters  ',\n",
              " 'nevertheless    that  technology  could  not  be  used  in  low  power  devices  such  as  smartphones  in  edge  ai  ',\n",
              " 'the  entrance  of  google  into  the  ai  chip  manufacturing  club  for  low  power  devices  can  be  the  next  revolution  in  this  industry  ',\n",
              " 'many  companies  such  as  foghorn  and  blinkai  are  working  in  edge  ai  using  currently  existing  ai  chips  in  the  market  ',\n",
              " 'however    the  efficacy  that  google  can  create  by  the  combination  of  tensorflow  and  tensor  will  be  game  changing  ',\n",
              " 'welcome  to  the  club    google  ',\n",
              " '    tensor  is  an  ai  chip  designed  by  ai  ',\n",
              " '    isn  t  that  cool  ',\n",
              " 'the  story  is  started  from  an  article  published  in  nature  titles    a  graph  placement  methodology  for  fast  chip  design    ',\n",
              " 'to  design  a  processing  chip    there  is  a  crucial  step  referred  to  as    floor  planning    where  the  engineering  team  must  place  a  large  number  of  components  such  that  a  series  of  physical  requirements  including  power  consumption  and  performance  get  satisfied  ',\n",
              " 'i  don  t  go  further  into  its  details  as  i  am  also  not  an  expert  in  hardware  engineering  ',\n",
              " 'however    when  you  have  a  large  series  of  choices  to  make  with  a  series  of  constraints  ai  can  kick  in  ',\n",
              " 'you  may  remember  how  the  alphago  project  defeated  a  professional  human  go  player  ',\n",
              " 'this  is  exactly  the  same  ',\n",
              " 'tensor  is  the  real  outcome  of  this  project  that  is  a  new  milestone  in  the  ai  industry  ',\n",
              " 'kudos    google  ',\n",
              " '    tensor  helps  us  build  ethical  ai  ',\n",
              " '    this  is  a  double  edged  sword  statement  ',\n",
              " 'ethical  ai  has  various  aspects  from  data  privacy  to  ai  for  all  ',\n",
              " 'tensor  helps  many  users  have  the  opportunity  to  try  the  latest  ai  advancement  while  they  have  no  concern  about  their  privacy  ',\n",
              " 'why  ',\n",
              " 'because  the  ai  engine  is  running  on  the  chip    and  no  data  is  sent  to  the  cloud  for  further  computation  ',\n",
              " 'on  the  other  hand    the  more  tightly  google  binds  ai  software  and  hardware    the  harder  it  will  be  for  other  companies  to  compete  ',\n",
              " 'i  don  t  want  to  see  days  that  other  companies  can  not  even  compete  on  performing  ai  inference    i  e      compete  on  using  ai  ',\n",
              " 'we  almost  lost  the  game  of  model  training  to  giant  tech  companies  ',\n",
              " 'it  would  be  a  nightmare  if  we  lose  the  game  on  ai  inference  to  them  as  well  ',\n",
              " 'that  is  why  i  believe    tensor  helps  us  build  ethical  ai    is  a  double  edged  sword  ']"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer= PorterStemmer()\n",
        "stemmer.stem(\"goes\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "gTziLw9uFvz7",
        "outputId": "f1bcc909-6de2-4f72-f57a-b269c8255da0"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'goe'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer.stem(\"history\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "-j6PoG5iHqWy",
        "outputId": "dbd70295-b0a5-48a7-ec63-455264741a95"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'histori'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in corpus:\n",
        "  words=nltk.word_tokenize(i)\n",
        "  print(words)\n",
        "\n",
        "  # therefore we got separate list of words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZ5T2_s1HxsT",
        "outputId": "ec787a44-996e-45c3-d90e-553be6a915bf"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['tensor', 'and', 'tensorflow', 'a', 'powerful', 'combo', 'the', 'google', 'brain', 'team', 'developed', 'an', 'advanced', 'ai', 'framework', 'named', 'tensorflow', 'years', 'back']\n",
            "['after', 'that', 'google', 'designed', 'its', 'own', 'processing', 'unit', 'named', 'tensor', 'processing', 'unit', 'or', 'tpu', 'to', 'perform', 'more', 'efficiently', 'with', 'the', 'tensorflow']\n",
            "['the', 'invention', 'of', 'tpu', 'was', 'a', 'revolution', 'in', 'ai', 'that', 'has', 'significantly', 'expedited', 'the', 'training', 'of', 'huge', 'machine', 'learning', 'models', 'with', 'millions', 'or', 'billions', 'of', 'parameters']\n",
            "['nevertheless', 'that', 'technology', 'could', 'not', 'be', 'used', 'in', 'low', 'power', 'devices', 'such', 'as', 'smartphones', 'in', 'edge', 'ai']\n",
            "['the', 'entrance', 'of', 'google', 'into', 'the', 'ai', 'chip', 'manufacturing', 'club', 'for', 'low', 'power', 'devices', 'can', 'be', 'the', 'next', 'revolution', 'in', 'this', 'industry']\n",
            "['many', 'companies', 'such', 'as', 'foghorn', 'and', 'blinkai', 'are', 'working', 'in', 'edge', 'ai', 'using', 'currently', 'existing', 'ai', 'chips', 'in', 'the', 'market']\n",
            "['however', 'the', 'efficacy', 'that', 'google', 'can', 'create', 'by', 'the', 'combination', 'of', 'tensorflow', 'and', 'tensor', 'will', 'be', 'game', 'changing']\n",
            "['welcome', 'to', 'the', 'club', 'google']\n",
            "['tensor', 'is', 'an', 'ai', 'chip', 'designed', 'by', 'ai']\n",
            "['isn', 't', 'that', 'cool']\n",
            "['the', 'story', 'is', 'started', 'from', 'an', 'article', 'published', 'in', 'nature', 'titles', 'a', 'graph', 'placement', 'methodology', 'for', 'fast', 'chip', 'design']\n",
            "['to', 'design', 'a', 'processing', 'chip', 'there', 'is', 'a', 'crucial', 'step', 'referred', 'to', 'as', 'floor', 'planning', 'where', 'the', 'engineering', 'team', 'must', 'place', 'a', 'large', 'number', 'of', 'components', 'such', 'that', 'a', 'series', 'of', 'physical', 'requirements', 'including', 'power', 'consumption', 'and', 'performance', 'get', 'satisfied']\n",
            "['i', 'don', 't', 'go', 'further', 'into', 'its', 'details', 'as', 'i', 'am', 'also', 'not', 'an', 'expert', 'in', 'hardware', 'engineering']\n",
            "['however', 'when', 'you', 'have', 'a', 'large', 'series', 'of', 'choices', 'to', 'make', 'with', 'a', 'series', 'of', 'constraints', 'ai', 'can', 'kick', 'in']\n",
            "['you', 'may', 'remember', 'how', 'the', 'alphago', 'project', 'defeated', 'a', 'professional', 'human', 'go', 'player']\n",
            "['this', 'is', 'exactly', 'the', 'same']\n",
            "['tensor', 'is', 'the', 'real', 'outcome', 'of', 'this', 'project', 'that', 'is', 'a', 'new', 'milestone', 'in', 'the', 'ai', 'industry']\n",
            "['kudos', 'google']\n",
            "['tensor', 'helps', 'us', 'build', 'ethical', 'ai']\n",
            "['this', 'is', 'a', 'double', 'edged', 'sword', 'statement']\n",
            "['ethical', 'ai', 'has', 'various', 'aspects', 'from', 'data', 'privacy', 'to', 'ai', 'for', 'all']\n",
            "['tensor', 'helps', 'many', 'users', 'have', 'the', 'opportunity', 'to', 'try', 'the', 'latest', 'ai', 'advancement', 'while', 'they', 'have', 'no', 'concern', 'about', 'their', 'privacy']\n",
            "['why']\n",
            "['because', 'the', 'ai', 'engine', 'is', 'running', 'on', 'the', 'chip', 'and', 'no', 'data', 'is', 'sent', 'to', 'the', 'cloud', 'for', 'further', 'computation']\n",
            "['on', 'the', 'other', 'hand', 'the', 'more', 'tightly', 'google', 'binds', 'ai', 'software', 'and', 'hardware', 'the', 'harder', 'it', 'will', 'be', 'for', 'other', 'companies', 'to', 'compete']\n",
            "['i', 'don', 't', 'want', 'to', 'see', 'days', 'that', 'other', 'companies', 'can', 'not', 'even', 'compete', 'on', 'performing', 'ai', 'inference', 'i', 'e', 'compete', 'on', 'using', 'ai']\n",
            "['we', 'almost', 'lost', 'the', 'game', 'of', 'model', 'training', 'to', 'giant', 'tech', 'companies']\n",
            "['it', 'would', 'be', 'a', 'nightmare', 'if', 'we', 'lose', 'the', 'game', 'on', 'ai', 'inference', 'to', 'them', 'as', 'well']\n",
            "['that', 'is', 'why', 'i', 'believe', 'tensor', 'helps', 'us', 'build', 'ethical', 'ai', 'is', 'a', 'double', 'edged', 'sword']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in corpus:\n",
        "   words=nltk.word_tokenize(i)\n",
        "\n",
        "   for i in words:\n",
        "     if i not in set(stopwords.words('english')):\n",
        "       print(stemmer.stem(i))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNgtGZR7H1qu",
        "outputId": "8604d01f-e53a-40f2-d365-e7635f20bee2"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor\n",
            "tensorflow\n",
            "power\n",
            "combo\n",
            "googl\n",
            "brain\n",
            "team\n",
            "develop\n",
            "advanc\n",
            "ai\n",
            "framework\n",
            "name\n",
            "tensorflow\n",
            "year\n",
            "back\n",
            "googl\n",
            "design\n",
            "process\n",
            "unit\n",
            "name\n",
            "tensor\n",
            "process\n",
            "unit\n",
            "tpu\n",
            "perform\n",
            "effici\n",
            "tensorflow\n",
            "invent\n",
            "tpu\n",
            "revolut\n",
            "ai\n",
            "significantli\n",
            "expedit\n",
            "train\n",
            "huge\n",
            "machin\n",
            "learn\n",
            "model\n",
            "million\n",
            "billion\n",
            "paramet\n",
            "nevertheless\n",
            "technolog\n",
            "could\n",
            "use\n",
            "low\n",
            "power\n",
            "devic\n",
            "smartphon\n",
            "edg\n",
            "ai\n",
            "entranc\n",
            "googl\n",
            "ai\n",
            "chip\n",
            "manufactur\n",
            "club\n",
            "low\n",
            "power\n",
            "devic\n",
            "next\n",
            "revolut\n",
            "industri\n",
            "mani\n",
            "compani\n",
            "foghorn\n",
            "blinkai\n",
            "work\n",
            "edg\n",
            "ai\n",
            "use\n",
            "current\n",
            "exist\n",
            "ai\n",
            "chip\n",
            "market\n",
            "howev\n",
            "efficaci\n",
            "googl\n",
            "creat\n",
            "combin\n",
            "tensorflow\n",
            "tensor\n",
            "game\n",
            "chang\n",
            "welcom\n",
            "club\n",
            "googl\n",
            "tensor\n",
            "ai\n",
            "chip\n",
            "design\n",
            "ai\n",
            "cool\n",
            "stori\n",
            "start\n",
            "articl\n",
            "publish\n",
            "natur\n",
            "titl\n",
            "graph\n",
            "placement\n",
            "methodolog\n",
            "fast\n",
            "chip\n",
            "design\n",
            "design\n",
            "process\n",
            "chip\n",
            "crucial\n",
            "step\n",
            "refer\n",
            "floor\n",
            "plan\n",
            "engin\n",
            "team\n",
            "must\n",
            "place\n",
            "larg\n",
            "number\n",
            "compon\n",
            "seri\n",
            "physic\n",
            "requir\n",
            "includ\n",
            "power\n",
            "consumpt\n",
            "perform\n",
            "get\n",
            "satisfi\n",
            "go\n",
            "detail\n",
            "also\n",
            "expert\n",
            "hardwar\n",
            "engin\n",
            "howev\n",
            "larg\n",
            "seri\n",
            "choic\n",
            "make\n",
            "seri\n",
            "constraint\n",
            "ai\n",
            "kick\n",
            "may\n",
            "rememb\n",
            "alphago\n",
            "project\n",
            "defeat\n",
            "profession\n",
            "human\n",
            "go\n",
            "player\n",
            "exactli\n",
            "tensor\n",
            "real\n",
            "outcom\n",
            "project\n",
            "new\n",
            "mileston\n",
            "ai\n",
            "industri\n",
            "kudo\n",
            "googl\n",
            "tensor\n",
            "help\n",
            "us\n",
            "build\n",
            "ethic\n",
            "ai\n",
            "doubl\n",
            "edg\n",
            "sword\n",
            "statement\n",
            "ethic\n",
            "ai\n",
            "variou\n",
            "aspect\n",
            "data\n",
            "privaci\n",
            "ai\n",
            "tensor\n",
            "help\n",
            "mani\n",
            "user\n",
            "opportun\n",
            "tri\n",
            "latest\n",
            "ai\n",
            "advanc\n",
            "concern\n",
            "privaci\n",
            "ai\n",
            "engin\n",
            "run\n",
            "chip\n",
            "data\n",
            "sent\n",
            "cloud\n",
            "comput\n",
            "hand\n",
            "tightli\n",
            "googl\n",
            "bind\n",
            "ai\n",
            "softwar\n",
            "hardwar\n",
            "harder\n",
            "compani\n",
            "compet\n",
            "want\n",
            "see\n",
            "day\n",
            "compani\n",
            "even\n",
            "compet\n",
            "perform\n",
            "ai\n",
            "infer\n",
            "e\n",
            "compet\n",
            "use\n",
            "ai\n",
            "almost\n",
            "lost\n",
            "game\n",
            "model\n",
            "train\n",
            "giant\n",
            "tech\n",
            "compani\n",
            "would\n",
            "nightmar\n",
            "lose\n",
            "game\n",
            "ai\n",
            "infer\n",
            "well\n",
            "believ\n",
            "tensor\n",
            "help\n",
            "us\n",
            "build\n",
            "ethic\n",
            "ai\n",
            "doubl\n",
            "edg\n",
            "sword\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemma= WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "QIJF26MaJeWH"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lemma.lemmatize(\"google\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "lWLk16jwJ74c",
        "outputId": "427dcfe0-bbc5-44da-b9ef-da45d35a2676"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'google'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemma.lemmatize(\"historical\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "4rOFQs-CKA6Q",
        "outputId": "23c67f9d-c91e-4848-be2b-a73ca5add457"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'historical'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in corpus:\n",
        "   words=nltk.word_tokenize(i)\n",
        "\n",
        "   for i in words:\n",
        "     if i not in set(stopwords.words('english')):\n",
        "       print(lemma.lemmatize(i))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CuM9FgVYK1V-",
        "outputId": "2c1938a6-dfcb-4142-8061-59b5d5852ee2"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor\n",
            "tensorflow\n",
            "powerful\n",
            "combo\n",
            "google\n",
            "brain\n",
            "team\n",
            "developed\n",
            "advanced\n",
            "ai\n",
            "framework\n",
            "named\n",
            "tensorflow\n",
            "year\n",
            "back\n",
            "google\n",
            "designed\n",
            "processing\n",
            "unit\n",
            "named\n",
            "tensor\n",
            "processing\n",
            "unit\n",
            "tpu\n",
            "perform\n",
            "efficiently\n",
            "tensorflow\n",
            "invention\n",
            "tpu\n",
            "revolution\n",
            "ai\n",
            "significantly\n",
            "expedited\n",
            "training\n",
            "huge\n",
            "machine\n",
            "learning\n",
            "model\n",
            "million\n",
            "billion\n",
            "parameter\n",
            "nevertheless\n",
            "technology\n",
            "could\n",
            "used\n",
            "low\n",
            "power\n",
            "device\n",
            "smartphones\n",
            "edge\n",
            "ai\n",
            "entrance\n",
            "google\n",
            "ai\n",
            "chip\n",
            "manufacturing\n",
            "club\n",
            "low\n",
            "power\n",
            "device\n",
            "next\n",
            "revolution\n",
            "industry\n",
            "many\n",
            "company\n",
            "foghorn\n",
            "blinkai\n",
            "working\n",
            "edge\n",
            "ai\n",
            "using\n",
            "currently\n",
            "existing\n",
            "ai\n",
            "chip\n",
            "market\n",
            "however\n",
            "efficacy\n",
            "google\n",
            "create\n",
            "combination\n",
            "tensorflow\n",
            "tensor\n",
            "game\n",
            "changing\n",
            "welcome\n",
            "club\n",
            "google\n",
            "tensor\n",
            "ai\n",
            "chip\n",
            "designed\n",
            "ai\n",
            "cool\n",
            "story\n",
            "started\n",
            "article\n",
            "published\n",
            "nature\n",
            "title\n",
            "graph\n",
            "placement\n",
            "methodology\n",
            "fast\n",
            "chip\n",
            "design\n",
            "design\n",
            "processing\n",
            "chip\n",
            "crucial\n",
            "step\n",
            "referred\n",
            "floor\n",
            "planning\n",
            "engineering\n",
            "team\n",
            "must\n",
            "place\n",
            "large\n",
            "number\n",
            "component\n",
            "series\n",
            "physical\n",
            "requirement\n",
            "including\n",
            "power\n",
            "consumption\n",
            "performance\n",
            "get\n",
            "satisfied\n",
            "go\n",
            "detail\n",
            "also\n",
            "expert\n",
            "hardware\n",
            "engineering\n",
            "however\n",
            "large\n",
            "series\n",
            "choice\n",
            "make\n",
            "series\n",
            "constraint\n",
            "ai\n",
            "kick\n",
            "may\n",
            "remember\n",
            "alphago\n",
            "project\n",
            "defeated\n",
            "professional\n",
            "human\n",
            "go\n",
            "player\n",
            "exactly\n",
            "tensor\n",
            "real\n",
            "outcome\n",
            "project\n",
            "new\n",
            "milestone\n",
            "ai\n",
            "industry\n",
            "kudos\n",
            "google\n",
            "tensor\n",
            "help\n",
            "u\n",
            "build\n",
            "ethical\n",
            "ai\n",
            "double\n",
            "edged\n",
            "sword\n",
            "statement\n",
            "ethical\n",
            "ai\n",
            "various\n",
            "aspect\n",
            "data\n",
            "privacy\n",
            "ai\n",
            "tensor\n",
            "help\n",
            "many\n",
            "user\n",
            "opportunity\n",
            "try\n",
            "latest\n",
            "ai\n",
            "advancement\n",
            "concern\n",
            "privacy\n",
            "ai\n",
            "engine\n",
            "running\n",
            "chip\n",
            "data\n",
            "sent\n",
            "cloud\n",
            "computation\n",
            "hand\n",
            "tightly\n",
            "google\n",
            "bind\n",
            "ai\n",
            "software\n",
            "hardware\n",
            "harder\n",
            "company\n",
            "compete\n",
            "want\n",
            "see\n",
            "day\n",
            "company\n",
            "even\n",
            "compete\n",
            "performing\n",
            "ai\n",
            "inference\n",
            "e\n",
            "compete\n",
            "using\n",
            "ai\n",
            "almost\n",
            "lost\n",
            "game\n",
            "model\n",
            "training\n",
            "giant\n",
            "tech\n",
            "company\n",
            "would\n",
            "nightmare\n",
            "lose\n",
            "game\n",
            "ai\n",
            "inference\n",
            "well\n",
            "believe\n",
            "tensor\n",
            "help\n",
            "u\n",
            "build\n",
            "ethical\n",
            "ai\n",
            "double\n",
            "edged\n",
            "sword\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "4q9HJJgaLTgp"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
      ],
      "metadata": {
        "id": "wxPMr42kMsGu"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv= CountVectorizer() # bag of words\n",
        "x=cv.fit_transform(corpus)\n",
        "cv.vocabulary_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSi2EXHaNAUZ",
        "outputId": "3a40c2d9-96dd-4527-fb32-8b39dd4f4fb1"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'tensor': 180,\n",
              " 'and': 11,\n",
              " 'tensorflow': 181,\n",
              " 'powerful': 151,\n",
              " 'combo': 34,\n",
              " 'the': 183,\n",
              " 'google': 81,\n",
              " 'brain': 23,\n",
              " 'team': 177,\n",
              " 'developed': 53,\n",
              " 'an': 10,\n",
              " 'advanced': 1,\n",
              " 'ai': 4,\n",
              " 'framework': 74,\n",
              " 'named': 125,\n",
              " 'years': 214,\n",
              " 'back': 16,\n",
              " 'after': 3,\n",
              " 'that': 182,\n",
              " 'designed': 51,\n",
              " 'its': 103,\n",
              " 'own': 140,\n",
              " 'processing': 153,\n",
              " 'unit': 195,\n",
              " 'or': 137,\n",
              " 'tpu': 192,\n",
              " 'to': 191,\n",
              " 'perform': 142,\n",
              " 'more': 123,\n",
              " 'efficiently': 60,\n",
              " 'with': 211,\n",
              " 'invention': 99,\n",
              " 'of': 134,\n",
              " 'was': 202,\n",
              " 'revolution': 161,\n",
              " 'in': 94,\n",
              " 'has': 86,\n",
              " 'significantly': 168,\n",
              " 'expedited': 68,\n",
              " 'training': 193,\n",
              " 'huge': 91,\n",
              " 'machine': 112,\n",
              " 'learning': 108,\n",
              " 'models': 122,\n",
              " 'millions': 120,\n",
              " 'billions': 20,\n",
              " 'parameters': 141,\n",
              " 'nevertheless': 127,\n",
              " 'technology': 179,\n",
              " 'could': 43,\n",
              " 'not': 132,\n",
              " 'be': 17,\n",
              " 'used': 197,\n",
              " 'low': 111,\n",
              " 'power': 150,\n",
              " 'devices': 54,\n",
              " 'such': 175,\n",
              " 'as': 14,\n",
              " 'smartphones': 169,\n",
              " 'edge': 57,\n",
              " 'entrance': 63,\n",
              " 'into': 98,\n",
              " 'chip': 28,\n",
              " 'manufacturing': 114,\n",
              " 'club': 32,\n",
              " 'for': 73,\n",
              " 'can': 26,\n",
              " 'next': 129,\n",
              " 'this': 188,\n",
              " 'industry': 96,\n",
              " 'many': 115,\n",
              " 'companies': 35,\n",
              " 'foghorn': 72,\n",
              " 'blinkai': 22,\n",
              " 'are': 12,\n",
              " 'working': 212,\n",
              " 'using': 199,\n",
              " 'currently': 46,\n",
              " 'existing': 67,\n",
              " 'chips': 29,\n",
              " 'market': 116,\n",
              " 'however': 90,\n",
              " 'efficacy': 59,\n",
              " 'create': 44,\n",
              " 'by': 25,\n",
              " 'combination': 33,\n",
              " 'will': 210,\n",
              " 'game': 77,\n",
              " 'changing': 27,\n",
              " 'welcome': 204,\n",
              " 'is': 100,\n",
              " 'isn': 101,\n",
              " 'cool': 42,\n",
              " 'story': 174,\n",
              " 'started': 171,\n",
              " 'from': 75,\n",
              " 'article': 13,\n",
              " 'published': 156,\n",
              " 'nature': 126,\n",
              " 'titles': 190,\n",
              " 'graph': 82,\n",
              " 'placement': 147,\n",
              " 'methodology': 118,\n",
              " 'fast': 70,\n",
              " 'design': 50,\n",
              " 'there': 186,\n",
              " 'crucial': 45,\n",
              " 'step': 173,\n",
              " 'referred': 158,\n",
              " 'floor': 71,\n",
              " 'planning': 148,\n",
              " 'where': 207,\n",
              " 'engineering': 62,\n",
              " 'must': 124,\n",
              " 'place': 146,\n",
              " 'large': 106,\n",
              " 'number': 133,\n",
              " 'components': 37,\n",
              " 'series': 167,\n",
              " 'physical': 145,\n",
              " 'requirements': 160,\n",
              " 'including': 95,\n",
              " 'consumption': 41,\n",
              " 'performance': 143,\n",
              " 'get': 78,\n",
              " 'satisfied': 164,\n",
              " 'don': 55,\n",
              " 'go': 80,\n",
              " 'further': 76,\n",
              " 'details': 52,\n",
              " 'am': 9,\n",
              " 'also': 8,\n",
              " 'expert': 69,\n",
              " 'hardware': 85,\n",
              " 'when': 206,\n",
              " 'you': 215,\n",
              " 'have': 87,\n",
              " 'choices': 30,\n",
              " 'make': 113,\n",
              " 'constraints': 40,\n",
              " 'kick': 104,\n",
              " 'may': 117,\n",
              " 'remember': 159,\n",
              " 'how': 89,\n",
              " 'alphago': 7,\n",
              " 'project': 155,\n",
              " 'defeated': 49,\n",
              " 'professional': 154,\n",
              " 'human': 92,\n",
              " 'player': 149,\n",
              " 'exactly': 66,\n",
              " 'same': 163,\n",
              " 'real': 157,\n",
              " 'outcome': 139,\n",
              " 'new': 128,\n",
              " 'milestone': 119,\n",
              " 'kudos': 105,\n",
              " 'helps': 88,\n",
              " 'us': 196,\n",
              " 'build': 24,\n",
              " 'ethical': 64,\n",
              " 'double': 56,\n",
              " 'edged': 58,\n",
              " 'sword': 176,\n",
              " 'statement': 172,\n",
              " 'various': 200,\n",
              " 'aspects': 15,\n",
              " 'data': 47,\n",
              " 'privacy': 152,\n",
              " 'all': 5,\n",
              " 'users': 198,\n",
              " 'opportunity': 136,\n",
              " 'try': 194,\n",
              " 'latest': 107,\n",
              " 'advancement': 2,\n",
              " 'while': 208,\n",
              " 'they': 187,\n",
              " 'no': 131,\n",
              " 'concern': 39,\n",
              " 'about': 0,\n",
              " 'their': 184,\n",
              " 'why': 209,\n",
              " 'because': 18,\n",
              " 'engine': 61,\n",
              " 'running': 162,\n",
              " 'on': 135,\n",
              " 'sent': 166,\n",
              " 'cloud': 31,\n",
              " 'computation': 38,\n",
              " 'other': 138,\n",
              " 'hand': 83,\n",
              " 'tightly': 189,\n",
              " 'binds': 21,\n",
              " 'software': 170,\n",
              " 'harder': 84,\n",
              " 'it': 102,\n",
              " 'compete': 36,\n",
              " 'want': 201,\n",
              " 'see': 165,\n",
              " 'days': 48,\n",
              " 'even': 65,\n",
              " 'performing': 144,\n",
              " 'inference': 97,\n",
              " 'we': 203,\n",
              " 'almost': 6,\n",
              " 'lost': 110,\n",
              " 'model': 121,\n",
              " 'giant': 79,\n",
              " 'tech': 178,\n",
              " 'would': 213,\n",
              " 'nightmare': 130,\n",
              " 'if': 93,\n",
              " 'lose': 109,\n",
              " 'them': 185,\n",
              " 'well': 205,\n",
              " 'believe': 19}"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "7mpky1s7NVK4",
        "outputId": "6d174fee-6ab3-45ca-e1dc-7445d8827263"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CountVectorizer()"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CountVectorizer()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x[0].toarray()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CAH_DpkaNWPZ",
        "outputId": "80c21a72-ed40-4d44-9fd5-f8a33c8bf2e4"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
              "        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 1, 0, 0, 1, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cv= CountVectorizer(binary=True) # only binary will be displayed present or not\n",
        "x=cv.fit_transform(corpus)\n",
        "cv.vocabulary_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMapX3yhNlQK",
        "outputId": "a14d0171-8ad4-4689-8c28-3a42a776e654"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'tensor': 180,\n",
              " 'and': 11,\n",
              " 'tensorflow': 181,\n",
              " 'powerful': 151,\n",
              " 'combo': 34,\n",
              " 'the': 183,\n",
              " 'google': 81,\n",
              " 'brain': 23,\n",
              " 'team': 177,\n",
              " 'developed': 53,\n",
              " 'an': 10,\n",
              " 'advanced': 1,\n",
              " 'ai': 4,\n",
              " 'framework': 74,\n",
              " 'named': 125,\n",
              " 'years': 214,\n",
              " 'back': 16,\n",
              " 'after': 3,\n",
              " 'that': 182,\n",
              " 'designed': 51,\n",
              " 'its': 103,\n",
              " 'own': 140,\n",
              " 'processing': 153,\n",
              " 'unit': 195,\n",
              " 'or': 137,\n",
              " 'tpu': 192,\n",
              " 'to': 191,\n",
              " 'perform': 142,\n",
              " 'more': 123,\n",
              " 'efficiently': 60,\n",
              " 'with': 211,\n",
              " 'invention': 99,\n",
              " 'of': 134,\n",
              " 'was': 202,\n",
              " 'revolution': 161,\n",
              " 'in': 94,\n",
              " 'has': 86,\n",
              " 'significantly': 168,\n",
              " 'expedited': 68,\n",
              " 'training': 193,\n",
              " 'huge': 91,\n",
              " 'machine': 112,\n",
              " 'learning': 108,\n",
              " 'models': 122,\n",
              " 'millions': 120,\n",
              " 'billions': 20,\n",
              " 'parameters': 141,\n",
              " 'nevertheless': 127,\n",
              " 'technology': 179,\n",
              " 'could': 43,\n",
              " 'not': 132,\n",
              " 'be': 17,\n",
              " 'used': 197,\n",
              " 'low': 111,\n",
              " 'power': 150,\n",
              " 'devices': 54,\n",
              " 'such': 175,\n",
              " 'as': 14,\n",
              " 'smartphones': 169,\n",
              " 'edge': 57,\n",
              " 'entrance': 63,\n",
              " 'into': 98,\n",
              " 'chip': 28,\n",
              " 'manufacturing': 114,\n",
              " 'club': 32,\n",
              " 'for': 73,\n",
              " 'can': 26,\n",
              " 'next': 129,\n",
              " 'this': 188,\n",
              " 'industry': 96,\n",
              " 'many': 115,\n",
              " 'companies': 35,\n",
              " 'foghorn': 72,\n",
              " 'blinkai': 22,\n",
              " 'are': 12,\n",
              " 'working': 212,\n",
              " 'using': 199,\n",
              " 'currently': 46,\n",
              " 'existing': 67,\n",
              " 'chips': 29,\n",
              " 'market': 116,\n",
              " 'however': 90,\n",
              " 'efficacy': 59,\n",
              " 'create': 44,\n",
              " 'by': 25,\n",
              " 'combination': 33,\n",
              " 'will': 210,\n",
              " 'game': 77,\n",
              " 'changing': 27,\n",
              " 'welcome': 204,\n",
              " 'is': 100,\n",
              " 'isn': 101,\n",
              " 'cool': 42,\n",
              " 'story': 174,\n",
              " 'started': 171,\n",
              " 'from': 75,\n",
              " 'article': 13,\n",
              " 'published': 156,\n",
              " 'nature': 126,\n",
              " 'titles': 190,\n",
              " 'graph': 82,\n",
              " 'placement': 147,\n",
              " 'methodology': 118,\n",
              " 'fast': 70,\n",
              " 'design': 50,\n",
              " 'there': 186,\n",
              " 'crucial': 45,\n",
              " 'step': 173,\n",
              " 'referred': 158,\n",
              " 'floor': 71,\n",
              " 'planning': 148,\n",
              " 'where': 207,\n",
              " 'engineering': 62,\n",
              " 'must': 124,\n",
              " 'place': 146,\n",
              " 'large': 106,\n",
              " 'number': 133,\n",
              " 'components': 37,\n",
              " 'series': 167,\n",
              " 'physical': 145,\n",
              " 'requirements': 160,\n",
              " 'including': 95,\n",
              " 'consumption': 41,\n",
              " 'performance': 143,\n",
              " 'get': 78,\n",
              " 'satisfied': 164,\n",
              " 'don': 55,\n",
              " 'go': 80,\n",
              " 'further': 76,\n",
              " 'details': 52,\n",
              " 'am': 9,\n",
              " 'also': 8,\n",
              " 'expert': 69,\n",
              " 'hardware': 85,\n",
              " 'when': 206,\n",
              " 'you': 215,\n",
              " 'have': 87,\n",
              " 'choices': 30,\n",
              " 'make': 113,\n",
              " 'constraints': 40,\n",
              " 'kick': 104,\n",
              " 'may': 117,\n",
              " 'remember': 159,\n",
              " 'how': 89,\n",
              " 'alphago': 7,\n",
              " 'project': 155,\n",
              " 'defeated': 49,\n",
              " 'professional': 154,\n",
              " 'human': 92,\n",
              " 'player': 149,\n",
              " 'exactly': 66,\n",
              " 'same': 163,\n",
              " 'real': 157,\n",
              " 'outcome': 139,\n",
              " 'new': 128,\n",
              " 'milestone': 119,\n",
              " 'kudos': 105,\n",
              " 'helps': 88,\n",
              " 'us': 196,\n",
              " 'build': 24,\n",
              " 'ethical': 64,\n",
              " 'double': 56,\n",
              " 'edged': 58,\n",
              " 'sword': 176,\n",
              " 'statement': 172,\n",
              " 'various': 200,\n",
              " 'aspects': 15,\n",
              " 'data': 47,\n",
              " 'privacy': 152,\n",
              " 'all': 5,\n",
              " 'users': 198,\n",
              " 'opportunity': 136,\n",
              " 'try': 194,\n",
              " 'latest': 107,\n",
              " 'advancement': 2,\n",
              " 'while': 208,\n",
              " 'they': 187,\n",
              " 'no': 131,\n",
              " 'concern': 39,\n",
              " 'about': 0,\n",
              " 'their': 184,\n",
              " 'why': 209,\n",
              " 'because': 18,\n",
              " 'engine': 61,\n",
              " 'running': 162,\n",
              " 'on': 135,\n",
              " 'sent': 166,\n",
              " 'cloud': 31,\n",
              " 'computation': 38,\n",
              " 'other': 138,\n",
              " 'hand': 83,\n",
              " 'tightly': 189,\n",
              " 'binds': 21,\n",
              " 'software': 170,\n",
              " 'harder': 84,\n",
              " 'it': 102,\n",
              " 'compete': 36,\n",
              " 'want': 201,\n",
              " 'see': 165,\n",
              " 'days': 48,\n",
              " 'even': 65,\n",
              " 'performing': 144,\n",
              " 'inference': 97,\n",
              " 'we': 203,\n",
              " 'almost': 6,\n",
              " 'lost': 110,\n",
              " 'model': 121,\n",
              " 'giant': 79,\n",
              " 'tech': 178,\n",
              " 'would': 213,\n",
              " 'nightmare': 130,\n",
              " 'if': 93,\n",
              " 'lose': 109,\n",
              " 'them': 185,\n",
              " 'well': 205,\n",
              " 'believe': 19}"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x[0].toarray()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3j1COgnHObce",
        "outputId": "a70d7cf3-3356-4102-9b71-54624ef91fc6"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
              "        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "_oWoU-i0OdxV",
        "outputId": "ddae206a-68ae-409b-97fb-e0e1d4e3a0f5"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'    tensor  and  tensorflow    a  powerful  combo      the  google  brain  team  developed  an  advanced  ai  framework  named  tensorflow  years  back  '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x= pd.DataFrame(x.toarray(), columns= cv.get_feature_names_out() )\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 988
        },
        "id": "FYVKnrEWO9RS",
        "outputId": "f52f92a3-993f-4d7f-cf94-fed31b7ea69a"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    about  advanced  advancement  after  ai  all  almost  alphago  also  am  \\\n",
              "0       0         1            0      0   1    0       0        0     0   0   \n",
              "1       0         0            0      1   0    0       0        0     0   0   \n",
              "2       0         0            0      0   1    0       0        0     0   0   \n",
              "3       0         0            0      0   1    0       0        0     0   0   \n",
              "4       0         0            0      0   1    0       0        0     0   0   \n",
              "5       0         0            0      0   1    0       0        0     0   0   \n",
              "6       0         0            0      0   0    0       0        0     0   0   \n",
              "7       0         0            0      0   0    0       0        0     0   0   \n",
              "8       0         0            0      0   1    0       0        0     0   0   \n",
              "9       0         0            0      0   0    0       0        0     0   0   \n",
              "10      0         0            0      0   0    0       0        0     0   0   \n",
              "11      0         0            0      0   0    0       0        0     0   0   \n",
              "12      0         0            0      0   0    0       0        0     1   1   \n",
              "13      0         0            0      0   1    0       0        0     0   0   \n",
              "14      0         0            0      0   0    0       0        1     0   0   \n",
              "15      0         0            0      0   0    0       0        0     0   0   \n",
              "16      0         0            0      0   1    0       0        0     0   0   \n",
              "17      0         0            0      0   0    0       0        0     0   0   \n",
              "18      0         0            0      0   1    0       0        0     0   0   \n",
              "19      0         0            0      0   0    0       0        0     0   0   \n",
              "20      0         0            0      0   1    1       0        0     0   0   \n",
              "21      1         0            1      0   1    0       0        0     0   0   \n",
              "22      0         0            0      0   0    0       0        0     0   0   \n",
              "23      0         0            0      0   1    0       0        0     0   0   \n",
              "24      0         0            0      0   1    0       0        0     0   0   \n",
              "25      0         0            0      0   1    0       0        0     0   0   \n",
              "26      0         0            0      0   0    0       1        0     0   0   \n",
              "27      0         0            0      0   1    0       0        0     0   0   \n",
              "28      0         0            0      0   1    0       0        0     0   0   \n",
              "\n",
              "    ...  when  where  while  why  will  with  working  would  years  you  \n",
              "0   ...     0      0      0    0     0     0        0      0      1    0  \n",
              "1   ...     0      0      0    0     0     1        0      0      0    0  \n",
              "2   ...     0      0      0    0     0     1        0      0      0    0  \n",
              "3   ...     0      0      0    0     0     0        0      0      0    0  \n",
              "4   ...     0      0      0    0     0     0        0      0      0    0  \n",
              "5   ...     0      0      0    0     0     0        1      0      0    0  \n",
              "6   ...     0      0      0    0     1     0        0      0      0    0  \n",
              "7   ...     0      0      0    0     0     0        0      0      0    0  \n",
              "8   ...     0      0      0    0     0     0        0      0      0    0  \n",
              "9   ...     0      0      0    0     0     0        0      0      0    0  \n",
              "10  ...     0      0      0    0     0     0        0      0      0    0  \n",
              "11  ...     0      1      0    0     0     0        0      0      0    0  \n",
              "12  ...     0      0      0    0     0     0        0      0      0    0  \n",
              "13  ...     1      0      0    0     0     1        0      0      0    1  \n",
              "14  ...     0      0      0    0     0     0        0      0      0    1  \n",
              "15  ...     0      0      0    0     0     0        0      0      0    0  \n",
              "16  ...     0      0      0    0     0     0        0      0      0    0  \n",
              "17  ...     0      0      0    0     0     0        0      0      0    0  \n",
              "18  ...     0      0      0    0     0     0        0      0      0    0  \n",
              "19  ...     0      0      0    0     0     0        0      0      0    0  \n",
              "20  ...     0      0      0    0     0     0        0      0      0    0  \n",
              "21  ...     0      0      1    0     0     0        0      0      0    0  \n",
              "22  ...     0      0      0    1     0     0        0      0      0    0  \n",
              "23  ...     0      0      0    0     0     0        0      0      0    0  \n",
              "24  ...     0      0      0    0     1     0        0      0      0    0  \n",
              "25  ...     0      0      0    0     0     0        0      0      0    0  \n",
              "26  ...     0      0      0    0     0     0        0      0      0    0  \n",
              "27  ...     0      0      0    0     0     0        0      1      0    0  \n",
              "28  ...     0      0      0    1     0     0        0      0      0    0  \n",
              "\n",
              "[29 rows x 216 columns]"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-b716b2dd-61ff-4c13-a2ad-61af1145a380\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>about</th>\n",
              "      <th>advanced</th>\n",
              "      <th>advancement</th>\n",
              "      <th>after</th>\n",
              "      <th>ai</th>\n",
              "      <th>all</th>\n",
              "      <th>almost</th>\n",
              "      <th>alphago</th>\n",
              "      <th>also</th>\n",
              "      <th>am</th>\n",
              "      <th>...</th>\n",
              "      <th>when</th>\n",
              "      <th>where</th>\n",
              "      <th>while</th>\n",
              "      <th>why</th>\n",
              "      <th>will</th>\n",
              "      <th>with</th>\n",
              "      <th>working</th>\n",
              "      <th>would</th>\n",
              "      <th>years</th>\n",
              "      <th>you</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>29 rows √ó 216 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b716b2dd-61ff-4c13-a2ad-61af1145a380')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-f2787b2e-8f76-4a1e-b978-2a5ca01cce9d\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f2787b2e-8f76-4a1e-b978-2a5ca01cce9d')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-f2787b2e-8f76-4a1e-b978-2a5ca01cce9d button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b716b2dd-61ff-4c13-a2ad-61af1145a380 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b716b2dd-61ff-4c13-a2ad-61af1145a380');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf= TfidfVectorizer()\n",
        "x=tf.fit_transform(corpus)"
      ],
      "metadata": {
        "id": "eDTOZYUUQMAK"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.toarray()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOve4xrFQmaL",
        "outputId": "66a9c8c9-1cf0-4787-a84c-85ee6e27757b"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.26420014, 0.        , ..., 0.        , 0.26420014,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       ...,\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.        , ..., 0.29867304, 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=pd.DataFrame(x.toarray(),columns= tf.get_feature_names_out())\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0ckek8MWQ8KC",
        "outputId": "7709efb5-540b-4aef-cb18-1379efc14ef3"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       about  advanced  advancement     after        ai       all    almost  \\\n",
              "0   0.000000    0.2642     0.000000  0.000000  0.111720  0.000000  0.000000   \n",
              "1   0.000000    0.0000     0.000000  0.230918  0.000000  0.000000  0.000000   \n",
              "2   0.000000    0.0000     0.000000  0.000000  0.093004  0.000000  0.000000   \n",
              "3   0.000000    0.0000     0.000000  0.000000  0.120739  0.000000  0.000000   \n",
              "4   0.000000    0.0000     0.000000  0.000000  0.113623  0.000000  0.000000   \n",
              "5   0.000000    0.0000     0.000000  0.000000  0.219569  0.000000  0.000000   \n",
              "6   0.000000    0.0000     0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "7   0.000000    0.0000     0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "8   0.000000    0.0000     0.000000  0.000000  0.419187  0.000000  0.000000   \n",
              "9   0.000000    0.0000     0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "10  0.000000    0.0000     0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "11  0.000000    0.0000     0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "12  0.000000    0.0000     0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "13  0.000000    0.0000     0.000000  0.000000  0.109396  0.000000  0.000000   \n",
              "14  0.000000    0.0000     0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "15  0.000000    0.0000     0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "16  0.000000    0.0000     0.000000  0.000000  0.134883  0.000000  0.000000   \n",
              "17  0.000000    0.0000     0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "18  0.000000    0.0000     0.000000  0.000000  0.227965  0.000000  0.000000   \n",
              "19  0.000000    0.0000     0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "20  0.000000    0.0000     0.000000  0.000000  0.293347  0.346861  0.000000   \n",
              "21  0.237845    0.0000     0.237845  0.000000  0.100575  0.000000  0.000000   \n",
              "22  0.000000    0.0000     0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "23  0.000000    0.0000     0.000000  0.000000  0.114125  0.000000  0.000000   \n",
              "24  0.000000    0.0000     0.000000  0.000000  0.102456  0.000000  0.000000   \n",
              "25  0.000000    0.0000     0.000000  0.000000  0.206884  0.000000  0.000000   \n",
              "26  0.000000    0.0000     0.000000  0.000000  0.000000  0.000000  0.340215   \n",
              "27  0.000000    0.0000     0.000000  0.000000  0.126297  0.000000  0.000000   \n",
              "28  0.000000    0.0000     0.000000  0.000000  0.138310  0.000000  0.000000   \n",
              "\n",
              "     alphago     also       am  ...      when     where     while       why  \\\n",
              "0   0.000000  0.00000  0.00000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "1   0.000000  0.00000  0.00000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "2   0.000000  0.00000  0.00000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "3   0.000000  0.00000  0.00000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "4   0.000000  0.00000  0.00000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "5   0.000000  0.00000  0.00000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "6   0.000000  0.00000  0.00000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "7   0.000000  0.00000  0.00000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "8   0.000000  0.00000  0.00000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "9   0.000000  0.00000  0.00000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "10  0.000000  0.00000  0.00000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "11  0.000000  0.00000  0.00000  ...  0.000000  0.185738  0.000000  0.000000   \n",
              "12  0.000000  0.29324  0.29324  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "13  0.000000  0.00000  0.00000  ...  0.258705  0.000000  0.000000  0.000000   \n",
              "14  0.307936  0.00000  0.00000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "15  0.000000  0.00000  0.00000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "16  0.000000  0.00000  0.00000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "17  0.000000  0.00000  0.00000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "18  0.000000  0.00000  0.00000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "19  0.000000  0.00000  0.00000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "20  0.000000  0.00000  0.00000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "21  0.000000  0.00000  0.00000  ...  0.000000  0.000000  0.237845  0.000000   \n",
              "22  0.000000  0.00000  0.00000  ...  0.000000  0.000000  0.000000  1.000000   \n",
              "23  0.000000  0.00000  0.00000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "24  0.000000  0.00000  0.00000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "25  0.000000  0.00000  0.00000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "26  0.000000  0.00000  0.00000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "27  0.000000  0.00000  0.00000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "28  0.000000  0.00000  0.00000  ...  0.000000  0.000000  0.000000  0.291317   \n",
              "\n",
              "        will      with   working     would   years       you  \n",
              "0   0.000000  0.000000  0.000000  0.000000  0.2642  0.000000  \n",
              "1   0.000000  0.187753  0.000000  0.000000  0.0000  0.000000  \n",
              "2   0.000000  0.178827  0.000000  0.000000  0.0000  0.000000  \n",
              "3   0.000000  0.000000  0.000000  0.000000  0.0000  0.000000  \n",
              "4   0.000000  0.000000  0.000000  0.000000  0.0000  0.000000  \n",
              "5   0.000000  0.000000  0.259624  0.000000  0.0000  0.000000  \n",
              "6   0.264670  0.000000  0.000000  0.000000  0.0000  0.000000  \n",
              "7   0.000000  0.000000  0.000000  0.000000  0.0000  0.000000  \n",
              "8   0.000000  0.000000  0.000000  0.000000  0.0000  0.000000  \n",
              "9   0.000000  0.000000  0.000000  0.000000  0.0000  0.000000  \n",
              "10  0.000000  0.000000  0.000000  0.000000  0.0000  0.000000  \n",
              "11  0.000000  0.000000  0.000000  0.000000  0.0000  0.000000  \n",
              "12  0.000000  0.000000  0.000000  0.000000  0.0000  0.000000  \n",
              "13  0.000000  0.210345  0.000000  0.000000  0.0000  0.230416  \n",
              "14  0.000000  0.000000  0.000000  0.000000  0.0000  0.274264  \n",
              "15  0.000000  0.000000  0.000000  0.000000  0.0000  0.000000  \n",
              "16  0.000000  0.000000  0.000000  0.000000  0.0000  0.000000  \n",
              "17  0.000000  0.000000  0.000000  0.000000  0.0000  0.000000  \n",
              "18  0.000000  0.000000  0.000000  0.000000  0.0000  0.000000  \n",
              "19  0.000000  0.000000  0.000000  0.000000  0.0000  0.000000  \n",
              "20  0.000000  0.000000  0.000000  0.000000  0.0000  0.000000  \n",
              "21  0.000000  0.000000  0.000000  0.000000  0.0000  0.000000  \n",
              "22  0.000000  0.000000  0.000000  0.000000  0.0000  0.000000  \n",
              "23  0.000000  0.000000  0.000000  0.000000  0.0000  0.000000  \n",
              "24  0.215799  0.000000  0.000000  0.000000  0.0000  0.000000  \n",
              "25  0.000000  0.000000  0.000000  0.000000  0.0000  0.000000  \n",
              "26  0.000000  0.000000  0.000000  0.000000  0.0000  0.000000  \n",
              "27  0.000000  0.000000  0.000000  0.298673  0.0000  0.000000  \n",
              "28  0.000000  0.000000  0.000000  0.000000  0.0000  0.000000  \n",
              "\n",
              "[29 rows x 216 columns]"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-3492694a-5d60-49a9-be96-56d474553d05\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>about</th>\n",
              "      <th>advanced</th>\n",
              "      <th>advancement</th>\n",
              "      <th>after</th>\n",
              "      <th>ai</th>\n",
              "      <th>all</th>\n",
              "      <th>almost</th>\n",
              "      <th>alphago</th>\n",
              "      <th>also</th>\n",
              "      <th>am</th>\n",
              "      <th>...</th>\n",
              "      <th>when</th>\n",
              "      <th>where</th>\n",
              "      <th>while</th>\n",
              "      <th>why</th>\n",
              "      <th>will</th>\n",
              "      <th>with</th>\n",
              "      <th>working</th>\n",
              "      <th>would</th>\n",
              "      <th>years</th>\n",
              "      <th>you</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.2642</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.111720</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.2642</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.230918</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.187753</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.093004</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.178827</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.120739</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.113623</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.219569</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.259624</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.264670</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.419187</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.185738</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.29324</td>\n",
              "      <td>0.29324</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.109396</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.258705</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.210345</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.230416</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.307936</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.274264</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.134883</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.227965</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.293347</td>\n",
              "      <td>0.346861</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0.237845</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.237845</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.100575</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.237845</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.114125</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.102456</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.215799</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.206884</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.340215</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.126297</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.298673</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.138310</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.291317</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>29 rows √ó 216 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3492694a-5d60-49a9-be96-56d474553d05')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-68e6d3b3-35a8-45ee-ac3e-7136ebb744a5\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-68e6d3b3-35a8-45ee-ac3e-7136ebb744a5')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-68e6d3b3-35a8-45ee-ac3e-7136ebb744a5 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3492694a-5d60-49a9-be96-56d474553d05 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3492694a-5d60-49a9-be96-56d474553d05');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0LAfL84RMOn",
        "outputId": "6aff3056-b244-45de-87e0-eafcdcbe29a1"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(29, 216)"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.get_feature_names_out()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rB8THPDtRRBg",
        "outputId": "7041b714-7131-46c0-b918-3e21351bcf65"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['about', 'advanced', 'advancement', 'after', 'ai', 'all', 'almost',\n",
              "       'alphago', 'also', 'am', 'an', 'and', 'are', 'article', 'as',\n",
              "       'aspects', 'back', 'be', 'because', 'believe', 'billions', 'binds',\n",
              "       'blinkai', 'brain', 'build', 'by', 'can', 'changing', 'chip',\n",
              "       'chips', 'choices', 'cloud', 'club', 'combination', 'combo',\n",
              "       'companies', 'compete', 'components', 'computation', 'concern',\n",
              "       'constraints', 'consumption', 'cool', 'could', 'create', 'crucial',\n",
              "       'currently', 'data', 'days', 'defeated', 'design', 'designed',\n",
              "       'details', 'developed', 'devices', 'don', 'double', 'edge',\n",
              "       'edged', 'efficacy', 'efficiently', 'engine', 'engineering',\n",
              "       'entrance', 'ethical', 'even', 'exactly', 'existing', 'expedited',\n",
              "       'expert', 'fast', 'floor', 'foghorn', 'for', 'framework', 'from',\n",
              "       'further', 'game', 'get', 'giant', 'go', 'google', 'graph', 'hand',\n",
              "       'harder', 'hardware', 'has', 'have', 'helps', 'how', 'however',\n",
              "       'huge', 'human', 'if', 'in', 'including', 'industry', 'inference',\n",
              "       'into', 'invention', 'is', 'isn', 'it', 'its', 'kick', 'kudos',\n",
              "       'large', 'latest', 'learning', 'lose', 'lost', 'low', 'machine',\n",
              "       'make', 'manufacturing', 'many', 'market', 'may', 'methodology',\n",
              "       'milestone', 'millions', 'model', 'models', 'more', 'must',\n",
              "       'named', 'nature', 'nevertheless', 'new', 'next', 'nightmare',\n",
              "       'no', 'not', 'number', 'of', 'on', 'opportunity', 'or', 'other',\n",
              "       'outcome', 'own', 'parameters', 'perform', 'performance',\n",
              "       'performing', 'physical', 'place', 'placement', 'planning',\n",
              "       'player', 'power', 'powerful', 'privacy', 'processing',\n",
              "       'professional', 'project', 'published', 'real', 'referred',\n",
              "       'remember', 'requirements', 'revolution', 'running', 'same',\n",
              "       'satisfied', 'see', 'sent', 'series', 'significantly',\n",
              "       'smartphones', 'software', 'started', 'statement', 'step', 'story',\n",
              "       'such', 'sword', 'team', 'tech', 'technology', 'tensor',\n",
              "       'tensorflow', 'that', 'the', 'their', 'them', 'there', 'they',\n",
              "       'this', 'tightly', 'titles', 'to', 'tpu', 'training', 'try',\n",
              "       'unit', 'us', 'used', 'users', 'using', 'various', 'want', 'was',\n",
              "       'we', 'welcome', 'well', 'when', 'where', 'while', 'why', 'will',\n",
              "       'with', 'working', 'would', 'years', 'you'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# hence we cleaned the document and extract the features, removed the unnecessary @,emoji etc and sorted"
      ],
      "metadata": {
        "id": "mEGYNK2tRjEV"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mAXcUiKIR1Ws"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}